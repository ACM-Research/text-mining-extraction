This is info about each script in this folder.
***

# Flesch-Kincaid Grade Level and Flesch Reading Ease
- This script processes a directory of .txt files and performs Flesch-Kincaid Grade Level and Flesch Reading Ease calculations on them.
- It has been designed with this dataset in mind, where the original data contains publisher and 3rd party corrections contained within brackets []. The dataset also has artifacts of '*' characters and newlines for formatting. The script removes these characters and messages because they are not representative of what was actually written by the author.
- The script then merges the entire text file into one string, which is then run through [textstat](https://github.com/shivam5992/textstat). The script returns these values into two columns in the output.txt, the first for Reading Level and the second for Grade Level.
- A separate script (reGraph.py) then analyzes a csv file of the scores returned by the script. For now, this csv is compiled manually from the output generated by the process above. This script then generates a boxplot using [seaborn](https://seaborn.pydata.org/index.html) of all scores across the different datasets.

## Libraries Used

- [textstat](https://github.com/shivam5992/textstat)
- [seaborn](https://seaborn.pydata.org/index.html)
- [matplotlib](https://matplotlib.org/stable/contents.html)

## Datasets Used

- [First-Person Narratives of the American South](https://docsouth.unc.edu/fpn/)
- [Project Gutenberg](https://www.gutenberg.org/)
- [BBC News Collection](https://www.kaggle.com/pariza/bbc-news-summary)

***
# N-Grams and Wordcloud Generation
This script processes a directory of .txt files and performs various N-Gram calculations on them.

# Sentiment Analysis
- This script takes in the Annotations csv file with demographic data and titles of the texts and returns a csv file with Polarity and Subjectivity of each text. File prep and processing is done in file_prep.py.
- We used [VADER Sentiment](https://github.com/cjhutto/vaderSentiment) to calculate Polarity (Positive/Neutral/Negative attitude) and used [TextBlob](textblob.readthedocs.io/) to calculate Subjectivity (Emotional-Factual content). Actual scoring is handled by file_scoring.py, called on by file_prep.
- Finally, file_display.py contains functions to visualize both scores by demographic. We used [Matplotlib](https://matplotlib.org/) for the graphs included in the Results folder.
## Libraries Used
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment)
- [TextBlob](textblob.readthedocs.io/)
- [Matplotlib](https://matplotlib.org/)

# Topic Modeling
The topicModeling.py script has been based on these libraries:
- [gensim](https://radimrehurek.com/gensim/)
- [pyLDAvis](https://github.com/bmabey/pyLDAvis)
- [nltk](https://www.nltk.org/)
- [pandas](https://pandas.pydata.org/)
- [matplotlib](https://matplotlib.org/stable/contents.html)

It iterates over a document or set of documents to produce a Latent Dirichlet Allocation model using gensim and outputs a visualization using pyLDAvis.
