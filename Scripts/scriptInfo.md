This is info about each script in this folder.
***

# Flesch-Kincaid Grade Level and Flesch Reading Ease
- This script processes a directory of .txt files and performs Flesch-Kincaid Grade Level and Flesch Reading Ease calculations on them.
- It has been designed with this dataset in mind, where the original data contains publisher and 3rd party corrections contained within brackets []. The dataset also has artifacts of '*' characters and newlines for formatting. The script removes these characters and messages because they are not representative of what was actually written by the author.
- The script then merges the entire text file into one string, which is then run through [textstat](https://github.com/shivam5992/textstat). The script returns these values into two columns in the output.txt, the first for Reading Level and the second for Grade Level.
- A separate script \(reGraph.py\) then analyzes a csv file of the scores returned by the script. For now, this csv is compiled manually from the output generated by the process above. This script then generates a boxplot using [seaborn](https://seaborn.pydata.org/index.html) of all scores across the different datasets.

## Libraries Used

- [textstat](https://github.com/shivam5992/textstat)
- [seaborn](https://seaborn.pydata.org/index.html)
- [matplotlib](https://matplotlib.org/stable/contents.html)

## Datasets Used

- [First-Person Narratives of the American South](https://docsouth.unc.edu/fpn/)
- [Project Gutenberg](https://www.gutenberg.org/)
- [BBC News Collection](https://www.kaggle.com/pariza/bbc-news-summary)

***
# N-Grams and Wordcloud Generation
An n-gram is a continuous sequence of n items from a given sample of text or speech. This script is designed to process a set of documents and performs various N-Gram calculations on them. After importing and installing the necessary libraries, the script is provided the path to the subdirectory containing all the historic documents in .txt format. These documents have been downloaded prior to the script being run. Then, with the necessary resources loaded, the script begins by “cleaning” all the text documents. This preprocessing includes removing stopwords, removing punctuation, and removing numbers, all of which would otherwise hinder the calculations. After that, the script begins the actual n-gram analysis, where it algorithmically goes through all the text documents and keeps a tally of all the bigram (two word phrases) and trigrams (three word phrases) in the document. Once it has made the necessary calculations, the script then plots the top 20 bigrams and trigrams as both a bar graph and a wordcloud for visualization. Meaningless prepositional phrases are also selectively discarded.

## Libraries Used

- [tm](https://cran.r-project.org/web/packages/tm/index.html)
- [ggplot2](https://cran.r-project.org/web/packages/ggplot2/index.html)
- [reshape2](https://cran.r-project.org/web/packages/reshape2/index.html)
- [wordcloud](https://cran.r-project.org/web/packages/wordcloud/)
- [Rweka](https://cran.r-project.org/web/packages/RWeka/index.html)

## Datasets Used

- [First-Person Narratives of the American South](https://docsouth.unc.edu/fpn/)

# Sentiment Analysis
- This script takes in the Annotations csv file with demographic data and titles of the texts and returns a csv file with Polarity and Subjectivity of each text. File prep and processing is done in file_prep.py.
- We used [VADER Sentiment](https://github.com/cjhutto/vaderSentiment) to calculate Polarity (Positive/Neutral/Negative attitude) and used [TextBlob](textblob.readthedocs.io/) to calculate Subjectivity (Emotional-Factual content). Actual scoring is handled by file_scoring.py, called on by file_prep.
- Finally, file_display.py contains functions to visualize both scores by demographic. We used [Matplotlib](https://matplotlib.org/) for the graphs included in the Results folder.
## Libraries Used
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment)
- [TextBlob](textblob.readthedocs.io/)
- [Matplotlib](https://matplotlib.org/)

# Topic Modeling
The topicModeling.py script has been based on these libraries:
- [gensim](https://radimrehurek.com/gensim/)
- [pyLDAvis](https://github.com/bmabey/pyLDAvis)
- [nltk](https://www.nltk.org/)
- [pandas](https://pandas.pydata.org/)
- [matplotlib](https://matplotlib.org/stable/contents.html)

It iterates over a document or set of documents to produce a Latent Dirichlet Allocation model using gensim and outputs a visualization using pyLDAvis.
